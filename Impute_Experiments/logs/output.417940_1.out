/cm/local/apps/slurm/var/spool/job417940/slurm_script: line 19: /common/ketrong/minconda3/etc/profile.d/conda.sh: No such file or directory
/cm/local/apps/slurm/var/spool/job417940/slurm_script: line 22: $'\nconda create --name tpot2devenv -c conda-forge python=3.10\n': command not found
/cm/local/apps/slurm/var/spool/job417940/slurm_script: line 27: $'\npip install -r requirements.txt\n': command not found
RunStart
2023-11-28 17:04:08.869784: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-11-28 17:04:08.904950: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2023-11-28 17:04:08.904973: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2023-11-28 17:04:08.905784: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-11-28 17:04:08.910865: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-28 17:04:11.569211: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
WARNING:tensorflow:From /home/ketrong/miniconda3/envs/tpot2devenv/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
start
working on 
tpot2_imputetest/Impute_Experiments/logs//small_run
loading data
tpot2_imputetest/Impute_Experiments/data/26_True.pkl
starting impute modules
running experiment 1/3 - Does large hyperparameter space improve reconstruction accuracy over simple
[I 2023-11-28 17:04:27,854] A new study created in memory with name: no-name-b976bca3-328a-4ebd-a825-c269453fc635
2023-11-28 17:04:32.362731: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2023-11-28 17:04:32.887908: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled
[I 2023-11-28 17:04:41,353] Trial 9 finished with value: 0.48695892397140617 and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.09, 'alpha': 45, 'iterations': 1}. Best is trial 9 with value: 0.48695892397140617.
[I 2023-11-28 17:04:41,621] Trial 14 finished with value: 0.47450602152028387 and parameters: {'model_name': 'GAIN', 'batch_size': 4, 'hint_rate': 0.27, 'alpha': 2, 'iterations': 1}. Best is trial 14 with value: 0.47450602152028387.
[I 2023-11-28 17:04:41,956] Trial 7 finished with value: 0.5354059439899688 and parameters: {'model_name': 'GAIN', 'batch_size': 11, 'hint_rate': 0.55, 'alpha': 47, 'iterations': 2}. Best is trial 14 with value: 0.47450602152028387.
[I 2023-11-28 17:04:42,386] Trial 1 finished with value: 0.4682899547896415 and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.21000000000000002, 'alpha': 74, 'iterations': 1}. Best is trial 1 with value: 0.4682899547896415.
[I 2023-11-28 17:04:43,422] Trial 0 finished with value: 0.4984063075828815 and parameters: {'model_name': 'GAIN', 'batch_size': 867, 'hint_rate': 0.09, 'alpha': 43, 'iterations': 4}. Best is trial 1 with value: 0.4682899547896415.
[I 2023-11-28 17:04:44,747] Trial 23 finished with value: 0.49606174771509964 and parameters: {'model_name': 'GAIN', 'batch_size': 43, 'hint_rate': 0.3, 'alpha': 41, 'iterations': 1}. Best is trial 1 with value: 0.4682899547896415.
[I 2023-11-28 17:04:45,102] Trial 47 finished with value: 0.4963157476025655 and parameters: {'model_name': 'GAIN', 'batch_size': 13, 'hint_rate': 0.45, 'alpha': 37, 'iterations': 1}. Best is trial 1 with value: 0.4682899547896415.
[I 2023-11-28 17:04:45,427] Trial 31 finished with value: 0.4389074365440588 and parameters: {'model_name': 'GAIN', 'batch_size': 28, 'hint_rate': 0.23, 'alpha': 28, 'iterations': 1}. Best is trial 31 with value: 0.4389074365440588.
[I 2023-11-28 17:04:45,803] Trial 32 finished with value: 0.4914031885373835 and parameters: {'model_name': 'GAIN', 'batch_size': 87, 'hint_rate': 0.45, 'alpha': 92, 'iterations': 1}. Best is trial 31 with value: 0.4389074365440588.
[I 2023-11-28 17:04:46,184] Trial 27 finished with value: 0.49300354185395767 and parameters: {'model_name': 'GAIN', 'batch_size': 18, 'hint_rate': 0.5700000000000001, 'alpha': 48, 'iterations': 2}. Best is trial 31 with value: 0.4389074365440588.
[I 2023-11-28 17:04:46,667] Trial 34 finished with value: 0.46802074525041104 and parameters: {'model_name': 'GAIN', 'batch_size': 4, 'hint_rate': 0.9600000000000001, 'alpha': 36, 'iterations': 1}. Best is trial 31 with value: 0.4389074365440588.
[I 2023-11-28 17:04:47,121] Trial 18 finished with value: 0.48397340862473504 and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.53, 'alpha': 49, 'iterations': 4}. Best is trial 31 with value: 0.4389074365440588.
[I 2023-11-28 17:04:49,531] Trial 6 finished with value: 0.446099033960027 and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.18000000000000002, 'alpha': 88, 'iterations': 5}. Best is trial 31 with value: 0.4389074365440588.
[I 2023-11-28 17:04:50,505] Trial 25 finished with value: 0.4565706293172037 and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.5700000000000001, 'alpha': 40, 'iterations': 7}. Best is trial 31 with value: 0.4389074365440588.
[I 2023-11-28 17:04:51,355] Trial 54 finished with value: 0.49536257647584736 and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.56, 'alpha': 68, 'iterations': 3}. Best is trial 31 with value: 0.4389074365440588.
[I 2023-11-28 17:04:52,891] Trial 50 finished with value: 0.45359348981732883 and parameters: {'model_name': 'GAIN', 'batch_size': 16, 'hint_rate': 0.26, 'alpha': 68, 'iterations': 8}. Best is trial 31 with value: 0.4389074365440588.
[I 2023-11-28 17:04:54,203] Trial 5 finished with value: 0.4116428923439791 and parameters: {'model_name': 'GAIN', 'batch_size': 25, 'hint_rate': 0.02, 'alpha': 42, 'iterations': 24}. Best is trial 5 with value: 0.4116428923439791.
[I 2023-11-28 17:04:57,162] Trial 58 finished with value: 0.4494764881122054 and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.9600000000000001, 'alpha': 17, 'iterations': 33}. Best is trial 5 with value: 0.4116428923439791.
[I 2023-11-28 17:04:57,793] Trial 44 finished with value: 0.3799598998446401 and parameters: {'model_name': 'GAIN', 'batch_size': 6, 'hint_rate': 0.88, 'alpha': 25, 'iterations': 39}. Best is trial 44 with value: 0.3799598998446401.
[I 2023-11-28 17:04:59,408] Trial 59 finished with value: 0.44616965836226796 and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.97, 'alpha': 19, 'iterations': 46}. Best is trial 44 with value: 0.3799598998446401.
[I 2023-11-28 17:05:00,641] Trial 61 finished with value: 0.414997075062939 and parameters: {'model_name': 'GAIN', 'batch_size': 54, 'hint_rate': 0.02, 'alpha': 18, 'iterations': 39}. Best is trial 44 with value: 0.3799598998446401.
[I 2023-11-28 17:05:01,009] Trial 63 finished with value: 0.4166640409941006 and parameters: {'model_name': 'GAIN', 'batch_size': 66, 'hint_rate': 0.04, 'alpha': 19, 'iterations': 32}. Best is trial 44 with value: 0.3799598998446401.
[I 2023-11-28 17:05:02,681] Trial 16 finished with value: 0.37520343380229676 and parameters: {'model_name': 'GAIN', 'batch_size': 489, 'hint_rate': 0.09, 'alpha': 9, 'iterations': 52}. Best is trial 16 with value: 0.37520343380229676.
[I 2023-11-28 17:05:05,122] Trial 64 finished with value: 0.3987345285697506 and parameters: {'model_name': 'GAIN', 'batch_size': 78, 'hint_rate': 0.03, 'alpha': 19, 'iterations': 46}. Best is trial 16 with value: 0.37520343380229676.
[I 2023-11-28 17:05:05,552] Trial 62 finished with value: 0.37763087676328655 and parameters: {'model_name': 'GAIN', 'batch_size': 54, 'hint_rate': 0.04, 'alpha': 19, 'iterations': 68}. Best is trial 16 with value: 0.37520343380229676.
[I 2023-11-28 17:05:06,196] Trial 56 finished with value: 0.3858842746062182 and parameters: {'model_name': 'GAIN', 'batch_size': 4, 'hint_rate': 0.59, 'alpha': 16, 'iterations': 72}. Best is trial 16 with value: 0.37520343380229676.
[I 2023-11-28 17:05:09,112] Trial 60 finished with value: 0.39083327124672496 and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.76, 'alpha': 16, 'iterations': 97}. Best is trial 16 with value: 0.37520343380229676.
[I 2023-11-28 17:05:13,488] Trial 53 finished with value: 0.37149012805666404 and parameters: {'model_name': 'GAIN', 'batch_size': 172, 'hint_rate': 0.4, 'alpha': 32, 'iterations': 115}. Best is trial 53 with value: 0.37149012805666404.
[I 2023-11-28 17:05:15,645] Trial 37 finished with value: 0.3723373130293182 and parameters: {'model_name': 'GAIN', 'batch_size': 85, 'hint_rate': 0.24000000000000002, 'alpha': 85, 'iterations': 144}. Best is trial 53 with value: 0.37149012805666404.
[I 2023-11-28 17:05:23,770] Trial 65 finished with value: 0.37072600631228225 and parameters: {'model_name': 'GAIN', 'batch_size': 78, 'hint_rate': 0.01, 'alpha': 22, 'iterations': 174}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:05:25,889] Trial 35 finished with value: 0.372421925531951 and parameters: {'model_name': 'GAIN', 'batch_size': 12, 'hint_rate': 0.08, 'alpha': 91, 'iterations': 249}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:05:27,187] Trial 40 finished with value: 0.3708959471904775 and parameters: {'model_name': 'GAIN', 'batch_size': 977, 'hint_rate': 0.5700000000000001, 'alpha': 11, 'iterations': 197}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:05:29,801] Trial 36 finished with value: 0.371829233675475 and parameters: {'model_name': 'GAIN', 'batch_size': 20, 'hint_rate': 0.29000000000000004, 'alpha': 80, 'iterations': 270}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:05:33,001] Trial 41 finished with value: 0.371065810239085 and parameters: {'model_name': 'GAIN', 'batch_size': 16, 'hint_rate': 0.21000000000000002, 'alpha': 94, 'iterations': 313}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:05:35,082] Trial 66 finished with value: 0.3719986705645037 and parameters: {'model_name': 'GAIN', 'batch_size': 8, 'hint_rate': 0.8, 'alpha': 19, 'iterations': 263}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:05:35,589] Trial 3 finished with value: 0.371574933474515 and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.34, 'alpha': 10, 'iterations': 321}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:05:40,760] Trial 52 finished with value: 0.371150712610689 and parameters: {'model_name': 'GAIN', 'batch_size': 20, 'hint_rate': 0.75, 'alpha': 57, 'iterations': 340}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:05:45,448] Trial 48 finished with value: 0.3708959471904775 and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.34, 'alpha': 90, 'iterations': 406}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:05:50,222] Trial 74 finished with value: 0.4693652488685351 and parameters: {'model_name': 'GAIN', 'batch_size': 177, 'hint_rate': 0.77, 'alpha': 0, 'iterations': 297}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:05:53,697] Trial 73 finished with value: 0.37570695015561795 and parameters: {'model_name': 'GAIN', 'batch_size': 184, 'hint_rate': 0.78, 'alpha': 1, 'iterations': 322}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:05:56,676] Trial 71 finished with value: 0.4749706054696893 and parameters: {'model_name': 'GAIN', 'batch_size': 211, 'hint_rate': 0.8, 'alpha': 0, 'iterations': 335}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:05:59,681] Trial 72 finished with value: 0.37309813475973685 and parameters: {'model_name': 'GAIN', 'batch_size': 165, 'hint_rate': 0.7100000000000001, 'alpha': 8, 'iterations': 382}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:06:00,730] Trial 69 finished with value: 0.3781311607672793 and parameters: {'model_name': 'GAIN', 'batch_size': 157, 'hint_rate': 0.8400000000000001, 'alpha': 2, 'iterations': 437}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:06:01,871] Trial 38 finished with value: 0.3717444862706875 and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.78, 'alpha': 9, 'iterations': 564}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:06:06,670] Trial 70 finished with value: 0.37427856118627073 and parameters: {'model_name': 'GAIN', 'batch_size': 167, 'hint_rate': 0.7000000000000001, 'alpha': 2, 'iterations': 457}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:06:12,285] Trial 13 finished with value: 0.37427856118627073 and parameters: {'model_name': 'GAIN', 'batch_size': 166, 'hint_rate': 0.87, 'alpha': 27, 'iterations': 559}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:06:14,988] Trial 68 finished with value: 0.37453102567446367 and parameters: {'model_name': 'GAIN', 'batch_size': 66, 'hint_rate': 0.73, 'alpha': 3, 'iterations': 565}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:06:21,149] Trial 78 finished with value: 0.37427856118627073 and parameters: {'model_name': 'GAIN', 'batch_size': 149, 'hint_rate': 0.35000000000000003, 'alpha': 100, 'iterations': 407}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:06:32,428] Trial 75 finished with value: 0.37149012805666404 and parameters: {'model_name': 'GAIN', 'batch_size': 203, 'hint_rate': 0.37, 'alpha': 4, 'iterations': 582}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:06:41,016] Trial 80 finished with value: 0.3737731206299665 and parameters: {'model_name': 'GAIN', 'batch_size': 195, 'hint_rate': 0.34, 'alpha': 99, 'iterations': 561}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:06:42,298] Trial 76 finished with value: 0.37343578019966045 and parameters: {'model_name': 'GAIN', 'batch_size': 362, 'hint_rate': 0.34, 'alpha': 4, 'iterations': 607}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:06:47,693] Trial 51 finished with value: 0.37191396176901526 and parameters: {'model_name': 'GAIN', 'batch_size': 193, 'hint_rate': 0.31, 'alpha': 80, 'iterations': 812}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:06:51,970] Trial 67 finished with value: 0.4412700578713509 and parameters: {'model_name': 'GAIN', 'batch_size': 6, 'hint_rate': 0.79, 'alpha': 0, 'iterations': 905}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:06:53,292] Trial 77 finished with value: 0.37528740010832773 and parameters: {'model_name': 'GAIN', 'batch_size': 164, 'hint_rate': 0.35000000000000003, 'alpha': 100, 'iterations': 672}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:07:02,807] Trial 83 finished with value: 0.37276018348136436 and parameters: {'model_name': 'GAIN', 'batch_size': 961, 'hint_rate': 0.16, 'alpha': 31, 'iterations': 578}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:07:07,130] Trial 79 finished with value: 0.3735201438695947 and parameters: {'model_name': 'GAIN', 'batch_size': 165, 'hint_rate': 0.34, 'alpha': 60, 'iterations': 777}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:07:10,443] Trial 101 finished with value: 0.3708959471904775 and parameters: {'model_name': 'GAIN', 'batch_size': 29, 'hint_rate': 0.15000000000000002, 'alpha': 60, 'iterations': 139}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:07:20,034] Trial 81 finished with value: 0.37318257475963207 and parameters: {'model_name': 'GAIN', 'batch_size': 868, 'hint_rate': 0.39, 'alpha': 100, 'iterations': 731}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:07:28,536] Trial 82 finished with value: 0.3717444862706875 and parameters: {'model_name': 'GAIN', 'batch_size': 910, 'hint_rate': 0.35000000000000003, 'alpha': 56, 'iterations': 760}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:07:31,118] Trial 104 finished with value: 0.37098088843679683 and parameters: {'model_name': 'GAIN', 'batch_size': 25, 'hint_rate': 0.16, 'alpha': 55, 'iterations': 173}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:07:40,803] Trial 105 finished with value: 0.371150712610689 and parameters: {'model_name': 'GAIN', 'batch_size': 29, 'hint_rate': 0.18000000000000002, 'alpha': 55, 'iterations': 181}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:07:44,537] Trial 26 finished with value: 0.371829233675475 and parameters: {'model_name': 'GAIN', 'batch_size': 27, 'hint_rate': 0.64, 'alpha': 41, 'iterations': 1444}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:07:52,020] Trial 85 finished with value: 0.371065810239085 and parameters: {'model_name': 'GAIN', 'batch_size': 722, 'hint_rate': 0.17, 'alpha': 99, 'iterations': 882}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:07:53,926] Trial 107 finished with value: 0.37123559556494024 and parameters: {'model_name': 'GAIN', 'batch_size': 29, 'hint_rate': 0.17, 'alpha': 94, 'iterations': 185}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:07:55,341] Trial 89 finished with value: 0.3721680303140308 and parameters: {'model_name': 'GAIN', 'batch_size': 735, 'hint_rate': 0.17, 'alpha': 56, 'iterations': 815}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:08:00,918] Trial 109 finished with value: 0.37098088843679683 and parameters: {'model_name': 'GAIN', 'batch_size': 25, 'hint_rate': 0.14, 'alpha': 63, 'iterations': 135}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:08:04,278] Trial 108 finished with value: 0.37072600631228225 and parameters: {'model_name': 'GAIN', 'batch_size': 35, 'hint_rate': 0.13, 'alpha': 65, 'iterations': 172}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:08:09,176] Trial 86 finished with value: 0.3714053032746342 and parameters: {'model_name': 'GAIN', 'batch_size': 924, 'hint_rate': 0.16, 'alpha': 96, 'iterations': 941}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:08:09,759] Trial 87 finished with value: 0.37208336007512044 and parameters: {'model_name': 'GAIN', 'batch_size': 671, 'hint_rate': 0.16, 'alpha': 96, 'iterations': 923}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:08:11,726] Trial 84 finished with value: 0.37191396176901526 and parameters: {'model_name': 'GAIN', 'batch_size': 991, 'hint_rate': 0.67, 'alpha': 2, 'iterations': 1027}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:08:14,516] Trial 113 finished with value: 0.3714053032746342 and parameters: {'model_name': 'GAIN', 'batch_size': 38, 'hint_rate': 0.13, 'alpha': 67, 'iterations': 96}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:08:16,756] Trial 94 finished with value: 0.37191396176901526 and parameters: {'model_name': 'GAIN', 'batch_size': 29, 'hint_rate': 0.15000000000000002, 'alpha': 100, 'iterations': 1073}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:08:19,222] Trial 90 finished with value: 0.3721680303140308 and parameters: {'model_name': 'GAIN', 'batch_size': 888, 'hint_rate': 0.15000000000000002, 'alpha': 100, 'iterations': 940}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:08:25,155] Trial 117 finished with value: 0.371065810239085 and parameters: {'model_name': 'GAIN', 'batch_size': 39, 'hint_rate': 0.11, 'alpha': 66, 'iterations': 113}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:08:27,326] Trial 114 finished with value: 0.37098088843679683 and parameters: {'model_name': 'GAIN', 'batch_size': 39, 'hint_rate': 0.11, 'alpha': 65, 'iterations': 152}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:08:30,284] Trial 115 finished with value: 0.3714053032746342 and parameters: {'model_name': 'GAIN', 'batch_size': 39, 'hint_rate': 0.11, 'alpha': 66, 'iterations': 137}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:08:30,621] Trial 116 finished with value: 0.3714053032746342 and parameters: {'model_name': 'GAIN', 'batch_size': 23, 'hint_rate': 0.21000000000000002, 'alpha': 64, 'iterations': 141}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:08:34,867] Trial 118 finished with value: 0.371150712610689 and parameters: {'model_name': 'GAIN', 'batch_size': 22, 'hint_rate': 0.09999999999999999, 'alpha': 51, 'iterations': 155}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:08:35,988] Trial 119 finished with value: 0.371150712610689 and parameters: {'model_name': 'GAIN', 'batch_size': 15, 'hint_rate': 0.21000000000000002, 'alpha': 52, 'iterations': 133}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:08:37,977] Trial 120 finished with value: 0.371065810239085 and parameters: {'model_name': 'GAIN', 'batch_size': 15, 'hint_rate': 0.11, 'alpha': 73, 'iterations': 145}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:08:40,149] Trial 91 finished with value: 0.371574933474515 and parameters: {'model_name': 'GAIN', 'batch_size': 608, 'hint_rate': 0.16, 'alpha': 97, 'iterations': 1041}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:08:45,709] Trial 15 finished with value: 0.37343578019966045 and parameters: {'model_name': 'GAIN', 'batch_size': 6, 'hint_rate': 0.55, 'alpha': 66, 'iterations': 1953}. Best is trial 65 with value: 0.37072600631228225.
[I 2023-11-28 17:08:49,200] Trial 122 finished with value: 0.37064100665363614 and parameters: {'model_name': 'GAIN', 'batch_size': 19, 'hint_rate': 0.08, 'alpha': 72, 'iterations': 158}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:08:50,866] Trial 121 finished with value: 0.37123559556494024 and parameters: {'model_name': 'GAIN', 'batch_size': 17, 'hint_rate': 0.06999999999999999, 'alpha': 76, 'iterations': 192}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:08:54,374] Trial 96 finished with value: 0.37385740817656277 and parameters: {'model_name': 'GAIN', 'batch_size': 25, 'hint_rate': 0.15000000000000002, 'alpha': 99, 'iterations': 1206}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:08:56,262] Trial 129 finished with value: 0.37629353435379553 and parameters: {'model_name': 'GAIN', 'batch_size': 12, 'hint_rate': 0.06999999999999999, 'alpha': 61, 'iterations': 82}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:08:58,197] Trial 123 finished with value: 0.3717444862706875 and parameters: {'model_name': 'GAIN', 'batch_size': 20, 'hint_rate': 0.060000000000000005, 'alpha': 74, 'iterations': 191}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:09:00,695] Trial 124 finished with value: 0.37098088843679683 and parameters: {'model_name': 'GAIN', 'batch_size': 15, 'hint_rate': 0.5, 'alpha': 52, 'iterations': 215}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:09:02,995] Trial 126 finished with value: 0.371065810239085 and parameters: {'model_name': 'GAIN', 'batch_size': 18, 'hint_rate': 0.51, 'alpha': 73, 'iterations': 207}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:09:05,876] Trial 125 finished with value: 0.37208336007512044 and parameters: {'model_name': 'GAIN', 'batch_size': 17, 'hint_rate': 0.06999999999999999, 'alpha': 73, 'iterations': 224}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:09:06,584] Trial 98 finished with value: 0.3717444862706875 and parameters: {'model_name': 'GAIN', 'batch_size': 30, 'hint_rate': 0.18000000000000002, 'alpha': 62, 'iterations': 1193}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:09:09,968] Trial 134 finished with value: 0.38078824157303603 and parameters: {'model_name': 'GAIN', 'batch_size': 10, 'hint_rate': 0.51, 'alpha': 45, 'iterations': 65}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:09:12,736] Trial 127 finished with value: 0.37064100665363614 and parameters: {'model_name': 'GAIN', 'batch_size': 33, 'hint_rate': 0.06999999999999999, 'alpha': 46, 'iterations': 243}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:09:13,501] Trial 128 finished with value: 0.3716597195414426 and parameters: {'model_name': 'GAIN', 'batch_size': 19, 'hint_rate': 0.06999999999999999, 'alpha': 73, 'iterations': 231}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:09:15,413] Trial 135 finished with value: 0.3725065188153889 and parameters: {'model_name': 'GAIN', 'batch_size': 48, 'hint_rate': 0.01, 'alpha': 71, 'iterations': 73}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:09:16,903] Trial 137 finished with value: 0.394444372947476 and parameters: {'model_name': 'GAIN', 'batch_size': 9, 'hint_rate': 0.27, 'alpha': 87, 'iterations': 63}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:09:19,543] Trial 136 finished with value: 0.37149012805666404 and parameters: {'model_name': 'GAIN', 'batch_size': 9, 'hint_rate': 0.6, 'alpha': 62, 'iterations': 95}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:09:23,733] Trial 130 finished with value: 0.371574933474515 and parameters: {'model_name': 'GAIN', 'batch_size': 10, 'hint_rate': 0.06999999999999999, 'alpha': 62, 'iterations': 224}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:09:25,301] Trial 97 finished with value: 0.37123559556494024 and parameters: {'model_name': 'GAIN', 'batch_size': 724, 'hint_rate': 0.14, 'alpha': 56, 'iterations': 1035}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:09:28,016] Trial 140 finished with value: 0.3746151426942047 and parameters: {'model_name': 'GAIN', 'batch_size': 47, 'hint_rate': 0.01, 'alpha': 59, 'iterations': 97}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:09:29,272] Trial 131 finished with value: 0.3716597195414426 and parameters: {'model_name': 'GAIN', 'batch_size': 10, 'hint_rate': 0.060000000000000005, 'alpha': 61, 'iterations': 250}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:09:30,174] Trial 133 finished with value: 0.3717444862706875 and parameters: {'model_name': 'GAIN', 'batch_size': 34, 'hint_rate': 0.51, 'alpha': 44, 'iterations': 212}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:09:30,830] Trial 141 finished with value: 0.37123559556494024 and parameters: {'model_name': 'GAIN', 'batch_size': 47, 'hint_rate': 0.59, 'alpha': 86, 'iterations': 94}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:09:33,810] Trial 142 finished with value: 0.37123559556494024 and parameters: {'model_name': 'GAIN', 'batch_size': 36, 'hint_rate': 0.62, 'alpha': 59, 'iterations': 103}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:09:34,662] Trial 143 finished with value: 0.371065810239085 and parameters: {'model_name': 'GAIN', 'batch_size': 36, 'hint_rate': 0.6, 'alpha': 23, 'iterations': 96}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:09:35,997] Trial 132 finished with value: 0.371574933474515 and parameters: {'model_name': 'GAIN', 'batch_size': 34, 'hint_rate': 0.06999999999999999, 'alpha': 45, 'iterations': 221}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:09:38,936] Trial 92 finished with value: 0.37123559556494024 and parameters: {'model_name': 'GAIN', 'batch_size': 809, 'hint_rate': 0.18000000000000002, 'alpha': 55, 'iterations': 1325}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:09:45,530] Trial 138 finished with value: 0.37098088843679683 and parameters: {'model_name': 'GAIN', 'batch_size': 10, 'hint_rate': 0.47000000000000003, 'alpha': 70, 'iterations': 260}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:09:51,638] Trial 139 finished with value: 0.3721680303140308 and parameters: {'model_name': 'GAIN', 'batch_size': 47, 'hint_rate': 0.26, 'alpha': 88, 'iterations': 253}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:09:55,917] Trial 93 finished with value: 0.371150712610689 and parameters: {'model_name': 'GAIN', 'batch_size': 812, 'hint_rate': 0.15000000000000002, 'alpha': 56, 'iterations': 1372}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:10:02,072] Trial 144 finished with value: 0.37276018348136436 and parameters: {'model_name': 'GAIN', 'batch_size': 34, 'hint_rate': 0.45, 'alpha': 24, 'iterations': 326}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:10:06,587] Trial 147 finished with value: 0.37208336007512044 and parameters: {'model_name': 'GAIN', 'batch_size': 35, 'hint_rate': 0.23, 'alpha': 12, 'iterations': 280}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:10:08,140] Trial 146 finished with value: 0.37309813475973685 and parameters: {'model_name': 'GAIN', 'batch_size': 36, 'hint_rate': 0.05, 'alpha': 13, 'iterations': 295}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:10:09,422] Trial 145 finished with value: 0.37259109289272235 and parameters: {'model_name': 'GAIN', 'batch_size': 48, 'hint_rate': 0.46, 'alpha': 13, 'iterations': 296}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:10:12,191] Trial 148 finished with value: 0.37149012805666404 and parameters: {'model_name': 'GAIN', 'batch_size': 35, 'hint_rate': 0.45, 'alpha': 70, 'iterations': 307}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:10:13,471] Trial 153 finished with value: 0.3719986705645037 and parameters: {'model_name': 'GAIN', 'batch_size': 24, 'hint_rate': 0.47000000000000003, 'alpha': 48, 'iterations': 302}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:10:14,457] Trial 150 finished with value: 0.37276018348136436 and parameters: {'model_name': 'GAIN', 'batch_size': 33, 'hint_rate': 0.47000000000000003, 'alpha': 23, 'iterations': 303}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:10:15,173] Trial 151 finished with value: 0.371829233675475 and parameters: {'model_name': 'GAIN', 'batch_size': 25, 'hint_rate': 0.43, 'alpha': 53, 'iterations': 286}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:10:16,994] Trial 149 finished with value: 0.3723373130293182 and parameters: {'model_name': 'GAIN', 'batch_size': 23, 'hint_rate': 0.23, 'alpha': 81, 'iterations': 320}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:10:21,213] Trial 154 finished with value: 0.37208336007512044 and parameters: {'model_name': 'GAIN', 'batch_size': 25, 'hint_rate': 0.23, 'alpha': 48, 'iterations': 314}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:10:22,746] Trial 152 finished with value: 0.371065810239085 and parameters: {'model_name': 'GAIN', 'batch_size': 22, 'hint_rate': 0.42000000000000004, 'alpha': 13, 'iterations': 345}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:10:25,829] Trial 100 finished with value: 0.37309813475973685 and parameters: {'model_name': 'GAIN', 'batch_size': 33, 'hint_rate': 0.18000000000000002, 'alpha': 57, 'iterations': 1670}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:10:28,905] Trial 33 finished with value: 0.371150712610689 and parameters: {'model_name': 'GAIN', 'batch_size': 225, 'hint_rate': 0.22, 'alpha': 78, 'iterations': 2284}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:10:31,700] Trial 155 finished with value: 0.37343578019966045 and parameters: {'model_name': 'GAIN', 'batch_size': 24, 'hint_rate': 0.25, 'alpha': 12, 'iterations': 325}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:10:34,216] Trial 102 finished with value: 0.3725065188153889 and parameters: {'model_name': 'GAIN', 'batch_size': 34, 'hint_rate': 0.64, 'alpha': 63, 'iterations': 1627}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:10:38,600] Trial 166 finished with value: 0.371574933474515 and parameters: {'model_name': 'GAIN', 'batch_size': 13, 'hint_rate': 0.54, 'alpha': 58, 'iterations': 153}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:10:41,273] Trial 28 finished with value: 0.37326699565761495 and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.68, 'alpha': 96, 'iterations': 2887}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:10:42,585] Trial 95 finished with value: 0.37123559556494024 and parameters: {'model_name': 'GAIN', 'batch_size': 933, 'hint_rate': 0.18000000000000002, 'alpha': 61, 'iterations': 1591}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:10:44,878] Trial 156 finished with value: 0.3762097926070473 and parameters: {'model_name': 'GAIN', 'batch_size': 26, 'hint_rate': 0.23, 'alpha': 83, 'iterations': 359}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:10:46,966] Trial 167 finished with value: 0.3714053032746342 and parameters: {'model_name': 'GAIN', 'batch_size': 57, 'hint_rate': 0.13, 'alpha': 76, 'iterations': 165}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:10:51,126] Trial 88 finished with value: 0.371065810239085 and parameters: {'model_name': 'GAIN', 'batch_size': 901, 'hint_rate': 0.66, 'alpha': 100, 'iterations': 1812}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:10:54,477] Trial 157 finished with value: 0.3741943685047003 and parameters: {'model_name': 'GAIN', 'batch_size': 24, 'hint_rate': 0.04, 'alpha': 53, 'iterations': 382}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:10:57,995] Trial 172 finished with value: 0.3708959471904775 and parameters: {'model_name': 'GAIN', 'batch_size': 14, 'hint_rate': 0.13, 'alpha': 90, 'iterations': 173}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:11:01,868] Trial 158 finished with value: 0.37343578019966045 and parameters: {'model_name': 'GAIN', 'batch_size': 22, 'hint_rate': 0.44, 'alpha': 14, 'iterations': 425}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:11:04,285] Trial 159 finished with value: 0.3741101568757494 and parameters: {'model_name': 'GAIN', 'batch_size': 25, 'hint_rate': 0.48000000000000004, 'alpha': 70, 'iterations': 395}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:11:06,088] Trial 162 finished with value: 0.3733513974666434 and parameters: {'model_name': 'GAIN', 'batch_size': 25, 'hint_rate': 0.48000000000000004, 'alpha': 48, 'iterations': 376}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:11:09,634] Trial 161 finished with value: 0.371065810239085 and parameters: {'model_name': 'GAIN', 'batch_size': 25, 'hint_rate': 0.48000000000000004, 'alpha': 81, 'iterations': 388}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:11:12,383] Trial 160 finished with value: 0.3737731206299665 and parameters: {'model_name': 'GAIN', 'batch_size': 24, 'hint_rate': 0.42000000000000004, 'alpha': 69, 'iterations': 450}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:11:14,845] Trial 180 finished with value: 0.371065810239085 and parameters: {'model_name': 'GAIN', 'batch_size': 14, 'hint_rate': 0.12, 'alpha': 92, 'iterations': 124}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:11:16,584] Trial 165 finished with value: 0.3714053032746342 and parameters: {'model_name': 'GAIN', 'batch_size': 13, 'hint_rate': 0.54, 'alpha': 79, 'iterations': 412}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:11:19,620] Trial 163 finished with value: 0.3722526812943849 and parameters: {'model_name': 'GAIN', 'batch_size': 14, 'hint_rate': 0.54, 'alpha': 53, 'iterations': 441}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:11:21,090] Trial 103 finished with value: 0.3721680303140308 and parameters: {'model_name': 'GAIN', 'batch_size': 35, 'hint_rate': 0.64, 'alpha': 57, 'iterations': 1860}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:11:23,024] Trial 182 finished with value: 0.371065810239085 and parameters: {'model_name': 'GAIN', 'batch_size': 7, 'hint_rate': 0.12, 'alpha': 90, 'iterations': 123}. Best is trial 122 with value: 0.37064100665363614.
[I 2023-11-28 17:11:23,788] Trial 164 finished with value: 0.3695342319106365 and parameters: {'model_name': 'GAIN', 'batch_size': 26, 'hint_rate': 0.13, 'alpha': 80, 'iterations': 475}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:11:26,693] Trial 181 finished with value: 0.37191396176901526 and parameters: {'model_name': 'GAIN', 'batch_size': 15, 'hint_rate': 0.09, 'alpha': 91, 'iterations': 136}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:11:29,106] Trial 183 finished with value: 0.371065810239085 and parameters: {'model_name': 'GAIN', 'batch_size': 19, 'hint_rate': 0.09999999999999999, 'alpha': 89, 'iterations': 129}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:11:31,520] Trial 184 finished with value: 0.37064100665363614 and parameters: {'model_name': 'GAIN', 'batch_size': 14, 'hint_rate': 0.09, 'alpha': 93, 'iterations': 123}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:11:32,965] Trial 168 finished with value: 0.3746151426942047 and parameters: {'model_name': 'GAIN', 'batch_size': 14, 'hint_rate': 0.13, 'alpha': 70, 'iterations': 482}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:11:35,645] Trial 185 finished with value: 0.37123559556494024 and parameters: {'model_name': 'GAIN', 'batch_size': 14, 'hint_rate': 0.09, 'alpha': 90, 'iterations': 120}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:11:38,002] Trial 169 finished with value: 0.37629353435379553 and parameters: {'model_name': 'GAIN', 'batch_size': 15, 'hint_rate': 0.12, 'alpha': 90, 'iterations': 490}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:11:38,792] Trial 170 finished with value: 0.3722526812943849 and parameters: {'model_name': 'GAIN', 'batch_size': 15, 'hint_rate': 0.53, 'alpha': 64, 'iterations': 452}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:11:40,547] Trial 187 finished with value: 0.3708959471904775 and parameters: {'model_name': 'GAIN', 'batch_size': 16, 'hint_rate': 0.09, 'alpha': 8, 'iterations': 123}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:11:42,411] Trial 171 finished with value: 0.3740259262866202 and parameters: {'model_name': 'GAIN', 'batch_size': 14, 'hint_rate': 0.31, 'alpha': 83, 'iterations': 453}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:11:43,057] Trial 186 finished with value: 0.37055598749741875 and parameters: {'model_name': 'GAIN', 'batch_size': 19, 'hint_rate': 0.09, 'alpha': 64, 'iterations': 168}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:11:47,146] Trial 106 finished with value: 0.37132045911515493 and parameters: {'model_name': 'GAIN', 'batch_size': 27, 'hint_rate': 0.17, 'alpha': 52, 'iterations': 1813}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:11:48,190] Trial 173 finished with value: 0.3719986705645037 and parameters: {'model_name': 'GAIN', 'batch_size': 14, 'hint_rate': 0.12, 'alpha': 91, 'iterations': 445}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:11:49,926] Trial 188 finished with value: 0.371065810239085 and parameters: {'model_name': 'GAIN', 'batch_size': 18, 'hint_rate': 0.09, 'alpha': 89, 'iterations': 176}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:11:50,854] Trial 189 finished with value: 0.3714053032746342 and parameters: {'model_name': 'GAIN', 'batch_size': 18, 'hint_rate': 0.09, 'alpha': 89, 'iterations': 164}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:11:51,712] Trial 191 finished with value: 0.3717444862706875 and parameters: {'model_name': 'GAIN', 'batch_size': 17, 'hint_rate': 0.09, 'alpha': 65, 'iterations': 168}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:11:52,520] Trial 190 finished with value: 0.371150712610689 and parameters: {'model_name': 'GAIN', 'batch_size': 17, 'hint_rate': 0.09, 'alpha': 65, 'iterations': 182}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:11:54,866] Trial 178 finished with value: 0.37098088843679683 and parameters: {'model_name': 'GAIN', 'batch_size': 14, 'hint_rate': 0.09, 'alpha': 90, 'iterations': 463}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:11:55,546] Trial 193 finished with value: 0.37038589063856087 and parameters: {'model_name': 'GAIN', 'batch_size': 17, 'hint_rate': 0.31, 'alpha': 64, 'iterations': 152}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:11:57,050] Trial 192 finished with value: 0.3708959471904775 and parameters: {'model_name': 'GAIN', 'batch_size': 19, 'hint_rate': 0.29000000000000004, 'alpha': 6, 'iterations': 169}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:11:57,677] Trial 175 finished with value: 0.373013675644957 and parameters: {'model_name': 'GAIN', 'batch_size': 13, 'hint_rate': 0.13, 'alpha': 90, 'iterations': 501}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:11:58,757] Trial 176 finished with value: 0.375539186382951 and parameters: {'model_name': 'GAIN', 'batch_size': 15, 'hint_rate': 0.13, 'alpha': 90, 'iterations': 480}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:11:59,575] Trial 177 finished with value: 0.37528740010832773 and parameters: {'model_name': 'GAIN', 'batch_size': 115, 'hint_rate': 0.09, 'alpha': 39, 'iterations': 427}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:12:00,578] Trial 174 finished with value: 0.37453102567446367 and parameters: {'model_name': 'GAIN', 'batch_size': 61, 'hint_rate': 0.13, 'alpha': 39, 'iterations': 479}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:12:01,221] Trial 195 finished with value: 0.371150712610689 and parameters: {'model_name': 'GAIN', 'batch_size': 18, 'hint_rate': 0.09, 'alpha': 65, 'iterations': 171}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:12:02,528] Trial 179 finished with value: 0.3726756477770272 and parameters: {'model_name': 'GAIN', 'batch_size': 14, 'hint_rate': 0.09, 'alpha': 93, 'iterations': 458}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:12:04,173] Trial 198 finished with value: 0.3716597195414426 and parameters: {'model_name': 'GAIN', 'batch_size': 19, 'hint_rate': 0.2, 'alpha': 94, 'iterations': 191}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:12:04,670] Trial 196 finished with value: 0.3717444862706875 and parameters: {'model_name': 'GAIN', 'batch_size': 124, 'hint_rate': 0.04, 'alpha': 65, 'iterations': 171}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:12:05,066] Trial 194 finished with value: 0.3704709488302066 and parameters: {'model_name': 'GAIN', 'batch_size': 117, 'hint_rate': 0.09, 'alpha': 40, 'iterations': 183}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:12:06,322] Trial 197 finished with value: 0.37123559556494024 and parameters: {'model_name': 'GAIN', 'batch_size': 96, 'hint_rate': 0.03, 'alpha': 64, 'iterations': 177}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:12:07,268] Trial 199 finished with value: 0.3716597195414426 and parameters: {'model_name': 'GAIN', 'batch_size': 106, 'hint_rate': 0.02, 'alpha': 64, 'iterations': 171}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:12:15,189] Trial 99 finished with value: 0.3708959471904775 and parameters: {'model_name': 'GAIN', 'batch_size': 24, 'hint_rate': 0.17, 'alpha': 63, 'iterations': 2600}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:12:17,070] Trial 112 finished with value: 0.371829233675475 and parameters: {'model_name': 'GAIN', 'batch_size': 38, 'hint_rate': 0.13, 'alpha': 84, 'iterations': 1954}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:12:24,571] Trial 57 finished with value: 0.376795593995833 and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.93, 'alpha': 13, 'iterations': 3869}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:12:39,561] Trial 111 finished with value: 0.371065810239085 and parameters: {'model_name': 'GAIN', 'batch_size': 653, 'hint_rate': 0.13, 'alpha': 83, 'iterations': 1881}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:12:44,136] Trial 110 finished with value: 0.3725065188153889 and parameters: {'model_name': 'GAIN', 'batch_size': 681, 'hint_rate': 0.15000000000000002, 'alpha': 90, 'iterations': 1933}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:12:57,974] Trial 11 finished with value: 0.371065810239085 and parameters: {'model_name': 'GAIN', 'batch_size': 6, 'hint_rate': 0.4, 'alpha': 17, 'iterations': 4607}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:13:18,213] Trial 8 finished with value: 0.3716597195414426 and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.08, 'alpha': 87, 'iterations': 5328}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:13:38,710] Trial 12 finished with value: 0.371065810239085 and parameters: {'model_name': 'GAIN', 'batch_size': 124, 'hint_rate': 0.62, 'alpha': 7, 'iterations': 5152}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:14:15,670] Trial 2 finished with value: 0.37123559556494024 and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.61, 'alpha': 90, 'iterations': 7425}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:14:22,653] Trial 24 finished with value: 0.371065810239085 and parameters: {'model_name': 'GAIN', 'batch_size': 9, 'hint_rate': 0.3, 'alpha': 4, 'iterations': 7193}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:14:38,922] Trial 21 finished with value: 0.3716597195414426 and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.8400000000000001, 'alpha': 65, 'iterations': 7882}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:15:35,783] Trial 55 finished with value: 0.371065810239085 and parameters: {'model_name': 'GAIN', 'batch_size': 186, 'hint_rate': 0.26, 'alpha': 97, 'iterations': 8212}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:17:12,763] Trial 29 finished with value: 0.371065810239085 and parameters: {'model_name': 'GAIN', 'batch_size': 26, 'hint_rate': 0.48000000000000004, 'alpha': 51, 'iterations': 13311}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:17:23,511] Trial 10 finished with value: 0.39228170093444414 and parameters: {'model_name': 'GAIN', 'batch_size': 134, 'hint_rate': 0.8300000000000001, 'alpha': 8, 'iterations': 12516}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:17:30,588] Trial 30 finished with value: 0.371065810239085 and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.73, 'alpha': 56, 'iterations': 14830}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:17:58,005] Trial 39 finished with value: 0.371065810239085 and parameters: {'model_name': 'GAIN', 'batch_size': 2, 'hint_rate': 0.9, 'alpha': 68, 'iterations': 16169}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:19:09,959] Trial 49 finished with value: 0.371065810239085 and parameters: {'model_name': 'GAIN', 'batch_size': 5, 'hint_rate': 0.46, 'alpha': 43, 'iterations': 21295}. Best is trial 164 with value: 0.3695342319106365.
[I 2023-11-28 17:20:44,311] Trial 42 finished with value: 0.3685951345045328 and parameters: {'model_name': 'GAIN', 'batch_size': 8, 'hint_rate': 0.5800000000000001, 'alpha': 30, 'iterations': 26728}. Best is trial 42 with value: 0.3685951345045328.
[I 2023-11-28 17:25:16,444] Trial 45 finished with value: 0.3735201438695947 and parameters: {'model_name': 'GAIN', 'batch_size': 21, 'hint_rate': 0.73, 'alpha': 92, 'iterations': 44379}. Best is trial 42 with value: 0.3685951345045328.
[I 2023-11-28 17:26:46,013] Trial 19 finished with value: 0.371065810239085 and parameters: {'model_name': 'GAIN', 'batch_size': 3, 'hint_rate': 0.87, 'alpha': 82, 'iterations': 58210}. Best is trial 42 with value: 0.3685951345045328.
[I 2023-11-28 17:27:45,336] Trial 22 finished with value: 0.3885694268833765 and parameters: {'model_name': 'GAIN', 'batch_size': 74, 'hint_rate': 0.5, 'alpha': 11, 'iterations': 51613}. Best is trial 42 with value: 0.3685951345045328.
[I 2023-11-28 17:28:27,969] Trial 4 finished with value: 0.371065810239085 and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.46, 'alpha': 19, 'iterations': 71711}. Best is trial 42 with value: 0.3685951345045328.
[I 2023-11-28 17:28:43,430] Trial 43 finished with value: 0.371065810239085 and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.73, 'alpha': 72, 'iterations': 73606}. Best is trial 42 with value: 0.3685951345045328.
[I 2023-11-28 17:29:03,366] Trial 17 finished with value: 0.371065810239085 and parameters: {'model_name': 'GAIN', 'batch_size': 1, 'hint_rate': 0.39, 'alpha': 71, 'iterations': 81633}. Best is trial 42 with value: 0.3685951345045328.
[I 2023-11-28 17:29:12,244] Trial 20 finished with value: 0.3880825992624175 and parameters: {'model_name': 'GAIN', 'batch_size': 84, 'hint_rate': 0.45, 'alpha': 55, 'iterations': 66727}. Best is trial 42 with value: 0.3685951345045328.
[I 2023-11-28 17:30:41,945] Trial 46 finished with value: 0.0 and parameters: {'model_name': 'GAIN', 'batch_size': 741, 'hint_rate': 0.77, 'alpha': 24, 'iterations': 61084}. Best is trial 46 with value: 0.0.
[[nan nan nan ... nan nan nan]
 [nan nan nan ... nan nan nan]
 [nan nan nan ... nan nan nan]
 ...
 [nan nan nan ... nan nan nan]
 [nan nan nan ... nan nan nan]
 [nan nan nan ... nan nan nan]]
auto-gain
Traceback (most recent call last):
  File "/common/ketrong/AutoImputeExp/tpot2_imputetest/Impute_Experiments/small_main.py", line 111, in <module>
    main()
  File "/common/ketrong/AutoImputeExp/tpot2_imputetest/Impute_Experiments/small_main.py", line 74, in main
    auto_gain_rmse = autoutils.rmse_loss(ori_data=X_test, imputed_data=auto_test_missing.to_numpy(), data_m=X_test_mask)
AttributeError: 'numpy.ndarray' object has no attribute 'to_numpy'
srun: error: esplhpc-cp002: task 0: Exited with exit code 1
